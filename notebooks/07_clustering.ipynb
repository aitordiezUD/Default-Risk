{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clustering Models",
   "id": "b3496eaa1e1b5147"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all, we are going to import the necessary libraries.",
   "id": "5f7ed3c07ea99ceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:45:39.814454Z",
     "start_time": "2024-12-10T21:45:39.810618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from cuml import NearestNeighbors\n",
    "import numpy as np\n",
    "import optuna\n",
    "import cuml\n",
    "from cuml.cluster import DBSCAN as cuDBSCAN\n",
    "from dask.array import asarray\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from cuml.metrics.cluster.silhouette_score import cython_silhouette_score as cu_silhouette_score\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import optuna.visualization as vis\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.decomposition import PCA"
   ],
   "id": "12b0315dd418cf7b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all, we are going to create a class to compute all the metrics. This class will be used to evaluate the performance of the models using the K Fold method.\n",
   "id": "b800e451d0a3f186"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T22:15:06.673165Z",
     "start_time": "2024-12-10T22:15:06.668072Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "class ClusteringMetrics:\n",
    "    def __init__(self, X, model):\n",
    "        # self.X = pd.DataFrame(X.get()).reset_index(drop=True)\n",
    "\n",
    "        if hasattr(X, 'get'):\n",
    "            self.X = pd.DataFrame(X.get()).reset_index(drop=True)\n",
    "        else:\n",
    "            self.X = pd.DataFrame(X).reset_index(drop=True)\n",
    "        self.model = model\n",
    "\n",
    "    def train(self):\n",
    "        self.model.fit(self.X)\n",
    "\n",
    "    def compute_internalEvaluation(self):\n",
    "        if hasattr(self.model, 'predict'):\n",
    "            # Use predict method if available (e.g., KMeans, GaussianMixture)\n",
    "            y_pred = self.model.predict(self.X)\n",
    "        elif hasattr(self.model, 'labels_'):\n",
    "            # Use labels_ for models like DBSCAN after fitting\n",
    "            y_pred = self.model.labels_\n",
    "        else:\n",
    "            # Raise an error if the model doesn't have any compatible method\n",
    "            raise AttributeError(\"The model does not have a valid method to predict cluster labels.\")\n",
    "\n",
    "        # print(\"Starting to compute metrics\")\n",
    "        self.shiloette_score = cu_silhouette_score(cp.asarray(self.X), cp.asarray(y_pred))\n",
    "        # print(\"Shiloette score computed\")\n",
    "        self.calinski_harabasz_score = calinski_harabasz_score(self.X, y_pred)\n",
    "        # print(\"Calinski Harabasz score computed\")\n",
    "        self.davies_bouldin_score = davies_bouldin_score(self.X, y_pred)\n",
    "        # print(\"Davies Bouldin score computed\")\n",
    "\n",
    "    def print_metrics(self):\n",
    "        print(f\"Silhouette Score: {self.shiloette_score}\")\n",
    "        print(f\"Calinski Harabasz Score: {self.calinski_harabasz_score}\")\n",
    "        print(f\"Davies Bouldin Score: {self.davies_bouldin_score}\")\n",
    "\n",
    "    def save_model(self, path):\n",
    "        directory = os.path.dirname(path)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        joblib.dump(self.model, path)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the data",
   "id": "de7502fa94451e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:46:26.835557Z",
     "start_time": "2024-12-10T21:46:26.735365Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_parquet('../data/processed/selected_features_df.parquet')",
   "id": "576a7235adaad1f1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are going to scale the data using the StandardScaler.",
   "id": "60ac32689baa2654"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:46:29.454166Z",
     "start_time": "2024-12-10T21:46:28.572553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)"
   ],
   "id": "928738ec36b678c3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's calculate the Hopkins statistic to check if the data is suitable for clustering.",
   "id": "b5d673e3bcff2abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T12:08:14.170645Z",
     "start_time": "2024-12-07T12:08:14.166537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    n = len(X)\n",
    "    m = int(0.1 * n)\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n",
    "\n",
    "    rand_X = np.random.rand(n, d)\n",
    "    ujd = []\n",
    "    wjd = []\n",
    "\n",
    "    for j in range(m):\n",
    "        u_dist, _ = nbrs.kneighbors(rand_X[j].reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[j].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    "\n",
    "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if np.isnan(H):\n",
    "        print(ujd, wjd)\n",
    "        H = 0\n",
    "\n",
    "    return H"
   ],
   "id": "610c16f1920a6551",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Hopkins statistic ranges from 0 to 1. The closer to 1, the more suitable the data is for clustering. Let's calculate the Hopkins statistic for the data.",
   "id": "70f6a58c1dce40d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T12:28:57.836930Z",
     "start_time": "2024-12-06T12:24:11.351507Z"
    }
   },
   "cell_type": "code",
   "source": "hopkins(df)",
   "id": "c0f81e8bd8481e75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645847043701986"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Hopkins statistic is close to 1, so the data is suitable for clustering.",
   "id": "83ed865ab2c3563b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DBSCAN",
   "id": "b5e21add7827ba3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are going to use the DBSCAN algorithm to cluster the data. We are going to use the Optuna library to find the best hyperparameters.",
   "id": "5d67868114006bca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:36:01.513839Z",
     "start_time": "2024-12-06T13:29:53.349126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "\n",
    "def objective(trial):\n",
    "    eps = trial.suggest_float('eps', 0.1, 1.0)\n",
    "    min_samples = trial.suggest_int('min_samples', 5, 10)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'cosine'])\n",
    "\n",
    "    model = cuDBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
    "    model.fit(df_scaled)\n",
    "    y_pred = model.labels_\n",
    "\n",
    "    # Verificar si hay al menos 2 clusters\n",
    "    if len(cp.unique(y_pred)) > 1:  # Usamos cupy para manejar el arreglo en GPU\n",
    "        return silhouette_score(df_scaled, y_pred)  # Devuelve el Silhouette score si hay más de 1 cluster\n",
    "    else:\n",
    "        return -1  # Devuelve un valor negativo si solo se encuentra un único cluster\n",
    "    study = optuna.create_study(direction='maximize', study_name='dbscan')\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    print(f\"Best parameters: {study.best_params}\")"
   ],
   "id": "716915c295157c48",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 14:29:53,352] A new study created in memory with name: dbscan\n",
      "[I 2024-12-06 14:46:08,489] Trial 0 finished with value: 0.06344437831203903 and parameters: {'eps': 0.45560417786879226, 'min_samples': 9, 'metric': 'cosine'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:01:01,110] Trial 1 finished with value: -0.08649164881054881 and parameters: {'eps': 0.2812818251401415, 'min_samples': 9, 'metric': 'cosine'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:05:37,931] Trial 2 finished with value: -1.0 and parameters: {'eps': 0.15472718863535367, 'min_samples': 10, 'metric': 'euclidean'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:20:50,951] Trial 3 finished with value: 0.12279910760197582 and parameters: {'eps': 0.529945149343017, 'min_samples': 10, 'metric': 'cosine'}. Best is trial 3 with value: 0.12279910760197582.\n",
      "[I 2024-12-06 15:36:01,502] Trial 4 finished with value: 0.15272329032663132 and parameters: {'eps': 0.9095320672300284, 'min_samples': 8, 'metric': 'cosine'}. Best is trial 4 with value: 0.15272329032663132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'eps': 0.9095320672300284, 'min_samples': 8, 'metric': 'cosine'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the bigger the eps, the better the silhouette score. Also, the cosine metric is better than the euclidean metric for this problem. Taking this into account we are going to create another Optuna study to find the best hyperparameters.",
   "id": "24332028cd3161fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T09:52:46.671717Z",
     "start_time": "2024-12-07T09:09:25.233474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "import gc\n",
    "\n",
    "df_scaled = cp.asarray(df_scaled)\n",
    "\n",
    "def objective(trial):\n",
    "    gc.collect()\n",
    "    cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "    eps = trial.suggest_float('eps', 1, 1.5)\n",
    "    min_samples = trial.suggest_int('min_samples', 5, 10)\n",
    "\n",
    "    model = cuDBSCAN(eps=eps, min_samples=min_samples, metric='cosine')\n",
    "    model.fit(df_scaled)\n",
    "    y_pred = model.labels_\n",
    "\n",
    "    # Verificar si hay al menos 2 clusters\n",
    "    if len(cp.unique(y_pred)) > 1:  # Usamos cupy para manejar el arreglo en GPU\n",
    "        return cu_silhouette_score(df_scaled, y_pred)  # Devuelve el Silhouette score si hay más de 1 cluster\n",
    "    else:\n",
    "        return -1  # Devuelve un valor negativo si solo se encuentra un único cluster\n",
    "study = optuna.create_study(direction='maximize', study_name='dbscan')\n",
    "study.optimize(objective, n_trials=5)\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ],
   "id": "e79f9ad4d94a5228",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 10:09:25,235] A new study created in memory with name: dbscan\n",
      "[I 2024-12-07 10:18:00,067] Trial 0 finished with value: 0.35992020990680346 and parameters: {'eps': 1.468031449624661, 'min_samples': 9}. Best is trial 0 with value: 0.35992020990680346.\n",
      "[I 2024-12-07 10:26:35,946] Trial 1 finished with value: 0.37549860352774733 and parameters: {'eps': 1.2027419903680259, 'min_samples': 8}. Best is trial 1 with value: 0.37549860352774733.\n",
      "[I 2024-12-07 10:35:13,500] Trial 2 finished with value: 0.38383985601186843 and parameters: {'eps': 1.2125524450750875, 'min_samples': 7}. Best is trial 2 with value: 0.38383985601186843.\n",
      "[I 2024-12-07 10:43:59,112] Trial 3 finished with value: 0.35992020990680346 and parameters: {'eps': 1.4344474832899103, 'min_samples': 6}. Best is trial 2 with value: 0.38383985601186843.\n",
      "[I 2024-12-07 10:52:46,669] Trial 4 finished with value: 0.1540651024846537 and parameters: {'eps': 1.001327955535295, 'min_samples': 6}. Best is trial 2 with value: 0.38383985601186843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'eps': 1.2125524450750875, 'min_samples': 7}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:24:08.772042Z",
     "start_time": "2024-12-10T22:15:19.873809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = cuDBSCAN(eps=1.2125524450750875, min_samples=7, metric='cosine')\n",
    "metrics = ClusteringMetrics(df_scaled, model)\n",
    "metrics.train()\n",
    "metrics.save_model('../models/dbscan.pkl')\n",
    "metrics.compute_internalEvaluation()\n",
    "metrics.print_metrics()"
   ],
   "id": "d721b417034b6187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.38383985601186843\n",
      "Calinski Harabasz Score: 6.71393677535788\n",
      "Davies Bouldin Score: 1.5755187609143613\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BIRCH",
   "id": "69a53b5fbe03692c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:58:33.651303Z",
     "start_time": "2024-12-10T21:58:33.509968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=4)  # Adjust this number to reduce dimensionality\n",
    "df_scaled_reduced = pca.fit_transform(df_scaled)"
   ],
   "id": "24b05576faa72650",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T16:25:59.781998Z",
     "start_time": "2024-12-07T15:39:45.517683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    # Sugerir valores para los hiperparámetros de BIRCH\n",
    "    threshold = trial.suggest_float('threshold', 0.01, 1.0)  # Umbral para la construcción del árbol\n",
    "    # n_clusters = trial.suggest_int('n_clusters', 2, 5)  # Número de clusters\n",
    "    branching_factor = trial.suggest_int('branching_factor', 10, 100)  # Número de hijos por nodo\n",
    "\n",
    "    model = Birch(threshold=threshold, n_clusters=3, branching_factor=branching_factor)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(df_scaled_reduced)\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Calcular el Silhouette Score para evaluar la calidad del clustering\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        score = silhouette_score(df_scaled_reduced, labels)\n",
    "        return score\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='birch_tuning')\n",
    "study.optimize(objective, n_trials=5)\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ],
   "id": "bfe99b3c90a1cfcc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 16:39:45,614] A new study created in memory with name: birch_tuning\n",
      "[I 2024-12-07 16:49:00,660] Trial 0 finished with value: 0.34914341637482804 and parameters: {'threshold': 0.5815544590284647, 'branching_factor': 65}. Best is trial 0 with value: 0.34914341637482804.\n",
      "[I 2024-12-07 16:58:12,682] Trial 1 finished with value: 0.3591458222679078 and parameters: {'threshold': 0.7481263824689723, 'branching_factor': 98}. Best is trial 1 with value: 0.3591458222679078.\n",
      "[I 2024-12-07 17:07:27,574] Trial 2 finished with value: 0.40124587744456613 and parameters: {'threshold': 0.9963391215347926, 'branching_factor': 25}. Best is trial 2 with value: 0.40124587744456613.\n",
      "[I 2024-12-07 17:16:40,971] Trial 3 finished with value: 0.3438450715954416 and parameters: {'threshold': 0.7656417232067172, 'branching_factor': 14}. Best is trial 2 with value: 0.40124587744456613.\n",
      "[I 2024-12-07 17:25:59,779] Trial 4 finished with value: 0.3469181031941854 and parameters: {'threshold': 0.3926784760210166, 'branching_factor': 43}. Best is trial 2 with value: 0.40124587744456613.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T17:12:46.780018Z",
     "start_time": "2024-12-07T16:26:41.505760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import Birch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)  # Adjust this number to reduce dimensionality\n",
    "df_scaled_reduced = pca.fit_transform(df_scaled)\n",
    "\n",
    "def objective(trial):\n",
    "    # Sugerir valores para los hiperparámetros de BIRCH\n",
    "    threshold = trial.suggest_float('threshold', 0.01, 1.0)  # Umbral para la construcción del árbol\n",
    "    # n_clusters = trial.suggest_int('n_clusters', 2, 5)  # Número de clusters\n",
    "    branching_factor = trial.suggest_int('branching_factor', 10, 100)  # Número de hijos por nodo\n",
    "\n",
    "    model = Birch(threshold=threshold, n_clusters=3, branching_factor=branching_factor)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(df_scaled_reduced)\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Calcular el Silhouette Score para evaluar la calidad del clustering\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        score = silhouette_score(df_scaled_reduced, labels)\n",
    "        return score\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='birch_tuning')\n",
    "study.optimize(objective, n_trials=5)"
   ],
   "id": "d2da11f5f3fb320",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 17:26:41,618] A new study created in memory with name: birch_tuning\n",
      "[I 2024-12-07 17:35:48,675] Trial 0 finished with value: 0.34974572749924693 and parameters: {'threshold': 0.9003977028532181, 'branching_factor': 99}. Best is trial 0 with value: 0.34974572749924693.\n",
      "[I 2024-12-07 17:45:02,581] Trial 1 finished with value: 0.3417716772528243 and parameters: {'threshold': 0.5573442455641573, 'branching_factor': 51}. Best is trial 0 with value: 0.34974572749924693.\n",
      "[I 2024-12-07 17:54:14,660] Trial 2 finished with value: 0.33049820651172246 and parameters: {'threshold': 0.9302214872562525, 'branching_factor': 93}. Best is trial 0 with value: 0.34974572749924693.\n",
      "[I 2024-12-07 18:03:31,409] Trial 3 finished with value: 0.4034668986672024 and parameters: {'threshold': 0.7238227929156842, 'branching_factor': 100}. Best is trial 3 with value: 0.4034668986672024.\n",
      "[I 2024-12-07 18:12:46,777] Trial 4 finished with value: 0.3954343902201493 and parameters: {'threshold': 0.8244520594796397, 'branching_factor': 63}. Best is trial 3 with value: 0.4034668986672024.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T18:48:14.069747Z",
     "start_time": "2024-12-07T18:01:59.424821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=4)  # Adjust this number to reduce dimensionality\n",
    "df_scaled_reduced = pca.fit_transform(df_scaled)\n",
    "\n",
    "def objective(trial):\n",
    "    # Sugerir valores para los hiperparámetros de BIRCH\n",
    "    threshold = trial.suggest_float('threshold', 1.83, 3.0)  # Umbral para la construcción del árbol\n",
    "    # n_clusters = trial.suggest_int('n_clusters', 2, 5)  # Número de clusters\n",
    "    branching_factor = trial.suggest_int('branching_factor', 10, 100)  # Número de hijos por nodo\n",
    "\n",
    "    model = Birch(threshold=threshold, n_clusters=3, branching_factor=branching_factor)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(df_scaled_reduced)\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Calcular el Silhouette Score para evaluar la calidad del clustering\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        score = silhouette_score(df_scaled_reduced, labels)\n",
    "        return score\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='birch_tuning')\n",
    "study.optimize(objective, n_trials=5)"
   ],
   "id": "f321ce25acd8906e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 19:01:59,643] A new study created in memory with name: birch_tuning\n",
      "[I 2024-12-07 19:11:21,279] Trial 0 finished with value: 0.18575780860921098 and parameters: {'threshold': 2.60466881925551, 'branching_factor': 46}. Best is trial 0 with value: 0.18575780860921098.\n",
      "[I 2024-12-07 19:20:31,179] Trial 1 finished with value: 0.3564872887967888 and parameters: {'threshold': 2.1540956836508287, 'branching_factor': 83}. Best is trial 1 with value: 0.3564872887967888.\n",
      "[I 2024-12-07 19:29:52,822] Trial 2 finished with value: 0.41516733727246385 and parameters: {'threshold': 2.228654160023864, 'branching_factor': 46}. Best is trial 2 with value: 0.41516733727246385.\n",
      "[I 2024-12-07 19:39:07,647] Trial 3 finished with value: 0.3983764555116041 and parameters: {'threshold': 2.7756256704572326, 'branching_factor': 61}. Best is trial 2 with value: 0.41516733727246385.\n",
      "[I 2024-12-07 19:48:14,067] Trial 4 finished with value: 0.338279702613758 and parameters: {'threshold': 2.7736347980784437, 'branching_factor': 93}. Best is trial 2 with value: 0.41516733727246385.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Computing the metrics for the best parameters.",
   "id": "cf0f90c5b510a261"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:01:26.808123Z",
     "start_time": "2024-12-10T21:58:33.659132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Birch(threshold=2.228654160023864, n_clusters=3, branching_factor=46)\n",
    "model.fit(df_scaled_reduced)\n",
    "#Save model\n",
    "# joblib.dump(model, '../models/birch.pkl')\n",
    "\n",
    "metrics = ClusteringMetrics(df_scaled_reduced, model)\n",
    "metrics.train()\n",
    "metrics.compute_internalEvaluation()\n",
    "metrics.save_model('../models/birch.pkl')\n",
    "metrics.print_metrics()"
   ],
   "id": "db0fc2d544823c90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.41516733727246374\n",
      "Calinski Harabasz Score: 69263.9973281745\n",
      "Davies Bouldin Score: 0.9181020942854774\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gaussian Mixture",
   "id": "dba0b245cb4fbcff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are going to use the Gaussian Mixture algorithm to cluster the data. We are going to use the Optuna library to find the best hyperparameters.",
   "id": "86e1a197036c069c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:02:21.816098Z",
     "start_time": "2024-12-10T20:16:58.385382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def objective(trial):\n",
    "    n_components = trial.suggest_int('n_components', 2, 5)\n",
    "    covariance_type = trial.suggest_categorical('covariance_type', ['full', 'tied', 'diag', 'spherical'])\n",
    "    tol = trial.suggest_float('tol', 1e-5, 1e-1)\n",
    "    reg_covar = trial.suggest_float('reg_covar', 1e-6, 1e-2)\n",
    "\n",
    "\n",
    "    model = GaussianMixture(n_components=n_components, covariance_type=covariance_type, tol=tol, reg_covar=reg_covar, random_state=42)\n",
    "    model.fit(df_scaled)\n",
    "    y_pred = model.predict(df_scaled)\n",
    "\n",
    "    return silhouette_score(df_scaled, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='gmm')\n",
    "study.optimize(objective, n_trials=5)"
   ],
   "id": "178ccff80759a332",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-10 21:16:58,431] A new study created in memory with name: gmm\n",
      "[I 2024-12-10 21:26:26,832] Trial 0 finished with value: 0.068944020380107 and parameters: {'n_components': 2, 'covariance_type': 'tied', 'tol': 0.02792127136333412, 'reg_covar': 0.007863629516834955}. Best is trial 0 with value: 0.068944020380107.\n",
      "[I 2024-12-10 21:35:01,073] Trial 1 finished with value: 0.06353784088589444 and parameters: {'n_components': 5, 'covariance_type': 'diag', 'tol': 0.02418755280161164, 'reg_covar': 0.0006082345442615693}. Best is trial 0 with value: 0.068944020380107.\n",
      "[I 2024-12-10 21:43:37,780] Trial 2 finished with value: 0.03497509670255373 and parameters: {'n_components': 3, 'covariance_type': 'spherical', 'tol': 0.0444942314395488, 'reg_covar': 0.009547804964557524}. Best is trial 0 with value: 0.068944020380107.\n",
      "[I 2024-12-10 21:53:19,753] Trial 3 finished with value: 0.06340238645125286 and parameters: {'n_components': 2, 'covariance_type': 'spherical', 'tol': 0.027655080965647047, 'reg_covar': 0.001014408894137987}. Best is trial 0 with value: 0.068944020380107.\n",
      "[I 2024-12-10 22:02:21,813] Trial 4 finished with value: 0.05952454746783261 and parameters: {'n_components': 3, 'covariance_type': 'full', 'tol': 0.0016969742230608445, 'reg_covar': 0.004195819448381651}. Best is trial 0 with value: 0.068944020380107.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Computing the metrics for the best parameters.",
   "id": "212d8c1856a3aec4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:39:26.396620Z",
     "start_time": "2024-12-10T21:35:43.149604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GaussianMixture(**study.best_params, random_state=42)\n",
    "\n",
    "metrics = ClusteringMetrics(df_scaled, model)\n",
    "metrics.train()\n",
    "metrics.compute_internalEvaluation()\n",
    "metrics.save_model('../models/gmm.pkl')\n",
    "metrics.print_metrics()"
   ],
   "id": "b0517a3ba050f2bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.06894402038010695\n",
      "Calinski Harabasz Score: 19626.39283621834\n",
      "Davies Bouldin Score: 2.5051416177208856\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:58:33.423775Z",
     "start_time": "2024-12-10T21:53:02.197303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = joblib.load('../models/gmm.pkl')\n",
    "\n",
    "metrics = ClusteringMetrics(df_scaled, model)\n",
    "metrics.compute_internalEvaluation()\n",
    "metrics.print_metrics()"
   ],
   "id": "edb3e3e52138fd6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.06894402038010695\n",
      "Calinski Harabasz Score: 19626.39283621834\n",
      "Davies Bouldin Score: 2.5051416177208856\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot the study results.",
   "id": "669da7b0cfafc30e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vis.plot_optimization_history(study)\n",
   "id": "75ecdc23aa464553"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vis.plot_parallel_coordinate(study)",
   "id": "df455e59bcc7b4da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vis.plot_slice(study)",
   "id": "67a851e92b73a5b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vis.plot_param_importances(study)",
   "id": "bf556107458aa192"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vis.plot_contour(study)",
   "id": "f0f30934d9f4cc89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
