{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clustering Models",
   "id": "b3496eaa1e1b5147"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all, we are going to import the necessary libraries.",
   "id": "5f7ed3c07ea99ceb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:47:47.925196Z",
     "start_time": "2024-12-07T10:47:47.921785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from cuml import NearestNeighbors\n",
    "import numpy as np\n",
    "import optuna\n",
    "import cuml\n",
    "from cuml.cluster import DBSCAN as cuDBSCAN\n",
    "from dask.array import asarray\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from cuml.metrics.cluster.silhouette_score import cython_silhouette_score as cu_silhouette_score\n",
    "\n"
   ],
   "id": "12b0315dd418cf7b",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all, we are going to create a class to compute all the metrics. This class will be used to evaluate the performance of the models using the K Fold method.\n",
   "id": "b800e451d0a3f186"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T10:47:49.230416Z",
     "start_time": "2024-12-07T10:47:49.226648Z"
    }
   },
   "source": [
    "class ClusteringMetrics:\n",
    "    def __init__(self, X, model):\n",
    "        self.X = pd.DataFrame(X.get()).reset_index(drop=True)\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def compute_internalEvaluation(self):\n",
    "        self.model.fit(self.X)\n",
    "        y_pred = self.model.labels_\n",
    "\n",
    "        self.shiloette_score = cu_silhouette_score(cp.asarray(self.X), y_pred)\n",
    "        self.calinski_harabasz_score = calinski_harabasz_score(self.X, y_pred)\n",
    "        self.davies_bouldin_score = davies_bouldin_score(self.X, y_pred)\n",
    "\n",
    "    def print_metrics(self):\n",
    "        print(f\"Silhouette Score: {self.shiloette_score}\")\n",
    "        print(f\"Calinski Harabasz Score: {self.calinski_harabasz_score}\")\n",
    "        print(f\"Davies Bouldin Score: {self.davies_bouldin_score}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the data",
   "id": "de7502fa94451e22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:47:51.370323Z",
     "start_time": "2024-12-07T10:47:51.278250Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_parquet('../data/processed/selected_features_df.parquet')",
   "id": "576a7235adaad1f1",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are going to scale the data using the StandardScaler.",
   "id": "60ac32689baa2654"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:47:53.758064Z",
     "start_time": "2024-12-07T10:47:52.721104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)"
   ],
   "id": "928738ec36b678c3",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's calculate the Hopkins statistic to check if the data is suitable for clustering.",
   "id": "b5d673e3bcff2abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T08:06:53.625792Z",
     "start_time": "2024-12-07T08:06:53.619716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hopkins(X):\n",
    "    d = X.shape[1]\n",
    "    n = len(X)\n",
    "    m = int(0.1 * n)\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n",
    "\n",
    "    rand_X = np.random.rand(n, d)\n",
    "    ujd = []\n",
    "    wjd = []\n",
    "\n",
    "    for j in range(m):\n",
    "        u_dist, _ = nbrs.kneighbors(rand_X[j].reshape(1, -1), 2, return_distance=True)\n",
    "        ujd.append(u_dist[0][1])\n",
    "        w_dist, _ = nbrs.kneighbors(X.iloc[j].values.reshape(1, -1), 2, return_distance=True)\n",
    "        wjd.append(w_dist[0][1])\n",
    "\n",
    "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "    if np.isnan(H):\n",
    "        print(ujd, wjd)\n",
    "        H = 0\n",
    "\n",
    "    return H"
   ],
   "id": "610c16f1920a6551",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Hopkins statistic ranges from 0 to 1. The closer to 1, the more suitable the data is for clustering. Let's calculate the Hopkins statistic for the data.",
   "id": "70f6a58c1dce40d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T12:28:57.836930Z",
     "start_time": "2024-12-06T12:24:11.351507Z"
    }
   },
   "cell_type": "code",
   "source": "hopkins(df)",
   "id": "c0f81e8bd8481e75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645847043701986"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Hopkins statistic is close to 1, so the data is suitable for clustering.",
   "id": "83ed865ab2c3563b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DBSCAN",
   "id": "b5e21add7827ba3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are going to use the DBSCAN algorithm to cluster the data. We are going to use the Optuna library to find the best hyperparameters.",
   "id": "5d67868114006bca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:36:01.513839Z",
     "start_time": "2024-12-06T13:29:53.349126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "\n",
    "def objective(trial):\n",
    "    eps = trial.suggest_float('eps', 0.1, 1.0)\n",
    "    min_samples = trial.suggest_int('min_samples', 5, 10)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'cosine'])\n",
    "\n",
    "    model = cuDBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
    "    model.fit(df_scaled)\n",
    "    y_pred = model.labels_\n",
    "\n",
    "    # Verificar si hay al menos 2 clusters\n",
    "    if len(cp.unique(y_pred)) > 1:  # Usamos cupy para manejar el arreglo en GPU\n",
    "        return silhouette_score(df_scaled, y_pred)  # Devuelve el Silhouette score si hay más de 1 cluster\n",
    "    else:\n",
    "        return -1  # Devuelve un valor negativo si solo se encuentra un único cluster\n",
    "    study = optuna.create_study(direction='maximize', study_name='dbscan')\n",
    "    study.optimize(objective, n_trials=5)\n",
    "    print(f\"Best parameters: {study.best_params}\")"
   ],
   "id": "716915c295157c48",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 14:29:53,352] A new study created in memory with name: dbscan\n",
      "[I 2024-12-06 14:46:08,489] Trial 0 finished with value: 0.06344437831203903 and parameters: {'eps': 0.45560417786879226, 'min_samples': 9, 'metric': 'cosine'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:01:01,110] Trial 1 finished with value: -0.08649164881054881 and parameters: {'eps': 0.2812818251401415, 'min_samples': 9, 'metric': 'cosine'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:05:37,931] Trial 2 finished with value: -1.0 and parameters: {'eps': 0.15472718863535367, 'min_samples': 10, 'metric': 'euclidean'}. Best is trial 0 with value: 0.06344437831203903.\n",
      "[I 2024-12-06 15:20:50,951] Trial 3 finished with value: 0.12279910760197582 and parameters: {'eps': 0.529945149343017, 'min_samples': 10, 'metric': 'cosine'}. Best is trial 3 with value: 0.12279910760197582.\n",
      "[I 2024-12-06 15:36:01,502] Trial 4 finished with value: 0.15272329032663132 and parameters: {'eps': 0.9095320672300284, 'min_samples': 8, 'metric': 'cosine'}. Best is trial 4 with value: 0.15272329032663132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'eps': 0.9095320672300284, 'min_samples': 8, 'metric': 'cosine'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the bigger the eps, the better the silhouette score. Also, the cosine metric is better than the euclidean metric for this problem. Taking this into account we are going to create another Optuna study to find the best hyperparameters.",
   "id": "24332028cd3161fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T09:52:46.671717Z",
     "start_time": "2024-12-07T09:09:25.233474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cupy as cp\n",
    "import gc\n",
    "\n",
    "df_scaled = cp.asarray(df_scaled)\n",
    "\n",
    "def objective(trial):\n",
    "    gc.collect()\n",
    "    cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "    eps = trial.suggest_float('eps', 1, 1.5)\n",
    "    min_samples = trial.suggest_int('min_samples', 5, 10)\n",
    "\n",
    "    model = cuDBSCAN(eps=eps, min_samples=min_samples, metric='cosine')\n",
    "    model.fit(df_scaled)\n",
    "    y_pred = model.labels_\n",
    "\n",
    "    # Verificar si hay al menos 2 clusters\n",
    "    if len(cp.unique(y_pred)) > 1:  # Usamos cupy para manejar el arreglo en GPU\n",
    "        return cu_silhouette_score(df_scaled, y_pred)  # Devuelve el Silhouette score si hay más de 1 cluster\n",
    "    else:\n",
    "        return -1  # Devuelve un valor negativo si solo se encuentra un único cluster\n",
    "study = optuna.create_study(direction='maximize', study_name='dbscan')\n",
    "study.optimize(objective, n_trials=5)\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ],
   "id": "e79f9ad4d94a5228",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 10:09:25,235] A new study created in memory with name: dbscan\n",
      "[I 2024-12-07 10:18:00,067] Trial 0 finished with value: 0.35992020990680346 and parameters: {'eps': 1.468031449624661, 'min_samples': 9}. Best is trial 0 with value: 0.35992020990680346.\n",
      "[I 2024-12-07 10:26:35,946] Trial 1 finished with value: 0.37549860352774733 and parameters: {'eps': 1.2027419903680259, 'min_samples': 8}. Best is trial 1 with value: 0.37549860352774733.\n",
      "[I 2024-12-07 10:35:13,500] Trial 2 finished with value: 0.38383985601186843 and parameters: {'eps': 1.2125524450750875, 'min_samples': 7}. Best is trial 2 with value: 0.38383985601186843.\n",
      "[I 2024-12-07 10:43:59,112] Trial 3 finished with value: 0.35992020990680346 and parameters: {'eps': 1.4344474832899103, 'min_samples': 6}. Best is trial 2 with value: 0.38383985601186843.\n",
      "[I 2024-12-07 10:52:46,669] Trial 4 finished with value: 0.1540651024846537 and parameters: {'eps': 1.001327955535295, 'min_samples': 6}. Best is trial 2 with value: 0.38383985601186843.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'eps': 1.2125524450750875, 'min_samples': 7}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:29:12.537634Z",
     "start_time": "2024-12-07T10:20:40.304173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = cuDBSCAN(eps=1.2125524450750875, min_samples=7, metric='cosine')\n",
    "metrics = ClusteringMetrics(df_scaled, model)\n",
    "metrics.compute_internalEvaluation()\n",
    "metrics.print_metrics()"
   ],
   "id": "d721b417034b6187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.38383985601186843\n",
      "Calinski Harabasz Score: 6.71393677535788\n",
      "Davies Bouldin Score: 1.5755187609143613\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BIRCH",
   "id": "69a53b5fbe03692c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:48:12.617011Z",
     "start_time": "2024-12-07T10:47:58.932367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# df_scaled = asarray(df_scaled)\n",
    "\n",
    "# Definir la función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Sugerir valores para los hiperparámetros de BIRCH\n",
    "    threshold = trial.suggest_float('threshold', 0.01, 1.0)  # Umbral para la construcción del árbol\n",
    "    n_clusters = trial.suggest_int('n_clusters', 2, 10)  # Número de clusters\n",
    "    # branching_factor = trial.suggest_int('branching_factor', 10, 100)  # Número de hijos por nodo\n",
    "\n",
    "    # Crear el modelo BIRCH con los hiperparámetros sugeridos\n",
    "    model = Birch(threshold=threshold, n_clusters=n_clusters)\n",
    "\n",
    "    # df_sparse = csr_matrix(df_scaled.get())\n",
    "    # model.fit(df_sparse)\n",
    "    # Entrenar el modelo\n",
    "    model.fit(df_scaled)\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Calcular el Silhouette Score para evaluar la calidad del clustering\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        score = silhouette_score(df_scaled, labels)\n",
    "        return score\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='birch_tuning')\n",
    "study.optimize(objective, n_trials=5)\n",
    "print(f\"Best parameters: {study.best_params}\")\n"
   ],
   "id": "bfe99b3c90a1cfcc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 11:47:58,934] A new study created in memory with name: birch_tuning\n",
      "[W 2024-12-07 11:48:12,517] Trial 0 failed with parameters: {'threshold': 0.29956887580750957, 'n_clusters': 3} because of the following error: MemoryError((35502197811,), dtype('float64')).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_9771/3399477042.py\", line 22, in objective\n",
      "    model.fit(df_scaled)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py\", line 524, in fit\n",
      "    return self._fit(X, partial=False)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py\", line 594, in _fit\n",
      "    self._global_clustering(X)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py\", line 735, in _global_clustering\n",
      "    self.subcluster_labels_ = clusterer.fit_predict(self.subcluster_centers_)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py\", line 1129, in fit_predict\n",
      "    return super().fit_predict(X, y)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py\", line 900, in fit_predict\n",
      "    self.fit(X, **kwargs)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py\", line 990, in fit\n",
      "    return self._fit(X)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py\", line 1076, in _fit\n",
      "    out = memory.cache(tree_builder)(\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/joblib/memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py\", line 314, in ward_tree\n",
      "    out = hierarchy.ward(X)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/cluster/hierarchy.py\", line 796, in ward\n",
      "    return linkage(y, method='ward', metric='euclidean')\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/cluster/hierarchy.py\", line 1024, in linkage\n",
      "    y = distance.pdist(y, metric)\n",
      "  File \"/home/aitor/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/spatial/distance.py\", line 2180, in pdist\n",
      "    return pdist_fn(X, out=out, **kwargs)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 265. GiB for an array with shape (35502197811,) and data type float64\n",
      "[W 2024-12-07 11:48:12,518] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 265. GiB for an array with shape (35502197811,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[67], line 33\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     32\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m, study_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbirch_tuning\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudy\u001B[38;5;241m.\u001B[39mbest_params\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    385\u001B[0m \n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    247\u001B[0m ):\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn[67], line 22\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m     17\u001B[0m model \u001B[38;5;241m=\u001B[39m Birch(threshold\u001B[38;5;241m=\u001B[39mthreshold, n_clusters\u001B[38;5;241m=\u001B[39mn_clusters)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# df_sparse = csr_matrix(df_scaled.get())\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# model.fit(df_sparse)\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Entrenar el modelo\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_scaled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m labels \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlabels_\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Calcular el Silhouette Score para evaluar la calidad del clustering\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py:524\u001B[0m, in \u001B[0;36mBirch.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    508\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;124;03m    Build a CF Tree for the input data.\u001B[39;00m\n\u001B[1;32m    510\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 524\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py:594\u001B[0m, in \u001B[0;36mBirch._fit\u001B[0;34m(self, X, partial)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubcluster_centers_ \u001B[38;5;241m=\u001B[39m centroids\n\u001B[1;32m    592\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_features_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubcluster_centers_\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 594\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_global_clustering\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_birch.py:735\u001B[0m, in \u001B[0;36mBirch._global_clustering\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    725\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    726\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of subclusters found (\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m) by BIRCH is less \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    727\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthan (\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m). Decrease the threshold.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    728\u001B[0m             \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mlen\u001B[39m(centroids), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_clusters),\n\u001B[1;32m    729\u001B[0m             ConvergenceWarning,\n\u001B[1;32m    730\u001B[0m         )\n\u001B[1;32m    731\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    732\u001B[0m     \u001B[38;5;66;03m# The global clustering step that clusters the subclusters of\u001B[39;00m\n\u001B[1;32m    733\u001B[0m     \u001B[38;5;66;03m# the leaves. It assumes the centroids of the subclusters as\u001B[39;00m\n\u001B[1;32m    734\u001B[0m     \u001B[38;5;66;03m# samples and finds the final centroids.\u001B[39;00m\n\u001B[0;32m--> 735\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubcluster_labels_ \u001B[38;5;241m=\u001B[39m \u001B[43mclusterer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubcluster_centers_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute_labels:\n\u001B[1;32m    738\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(X)\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:1129\u001B[0m, in \u001B[0;36mAgglomerativeClustering.fit_predict\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1109\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001B[39;00m\n\u001B[1;32m   1110\u001B[0m \n\u001B[1;32m   1111\u001B[0m \u001B[38;5;124;03m    In addition to fitting, this method also return the result of the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;124;03m        Cluster labels.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py:900\u001B[0m, in \u001B[0;36mClusterMixin.fit_predict\u001B[0;34m(self, X, y, **kwargs)\u001B[0m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001B[39;00m\n\u001B[1;32m    879\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    896\u001B[0m \u001B[38;5;124;03m    Cluster labels.\u001B[39;00m\n\u001B[1;32m    897\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m--> 900\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels_\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:990\u001B[0m, in \u001B[0;36mAgglomerativeClustering.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    972\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001B[39;00m\n\u001B[1;32m    973\u001B[0m \n\u001B[1;32m    974\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    987\u001B[0m \u001B[38;5;124;03m    Returns the fitted instance.\u001B[39;00m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    989\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, ensure_min_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 990\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:1076\u001B[0m, in \u001B[0;36mAgglomerativeClustering._fit\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1072\u001B[0m distance_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistance_threshold\n\u001B[1;32m   1074\u001B[0m return_distance \u001B[38;5;241m=\u001B[39m (distance_threshold \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_distances\n\u001B[0;32m-> 1076\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmemory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtree_builder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconnectivity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconnectivity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_connected_components_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_leaves_, parents) \u001B[38;5;241m=\u001B[39m out[\n\u001B[1;32m   1084\u001B[0m     :\u001B[38;5;241m4\u001B[39m\n\u001B[1;32m   1085\u001B[0m ]\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_distance:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/joblib/memory.py:312\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:314\u001B[0m, in \u001B[0;36mward_tree\u001B[0;34m(X, connectivity, n_clusters, return_distance)\u001B[0m\n\u001B[1;32m    302\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    303\u001B[0m         (\n\u001B[1;32m    304\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPartial build of the tree is implemented \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    311\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    312\u001B[0m     )\n\u001B[1;32m    313\u001B[0m X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrequire(X, requirements\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 314\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mhierarchy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    315\u001B[0m children_ \u001B[38;5;241m=\u001B[39m out[:, :\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mintp)\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_distance:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/cluster/hierarchy.py:796\u001B[0m, in \u001B[0;36mward\u001B[0;34m(y)\u001B[0m\n\u001B[1;32m    700\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mward\u001B[39m(y):\n\u001B[1;32m    701\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;124;03m    Perform Ward's linkage on a condensed distance matrix.\u001B[39;00m\n\u001B[1;32m    703\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    794\u001B[0m \n\u001B[1;32m    795\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlinkage\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mward\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meuclidean\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/cluster/hierarchy.py:1024\u001B[0m, in \u001B[0;36mlinkage\u001B[0;34m(y, method, metric, optimal_ordering)\u001B[0m\n\u001B[1;32m   1018\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(np\u001B[38;5;241m.\u001B[39mdiag(y), \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m   1019\u001B[0m             xp\u001B[38;5;241m.\u001B[39mall(y \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(y, y\u001B[38;5;241m.\u001B[39mT)):\n\u001B[1;32m   1020\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe symmetric non-negative hollow observation \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1021\u001B[0m                       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatrix looks suspiciously like an uncondensed \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1022\u001B[0m                       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistance matrix\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1023\u001B[0m                       ClusterWarning, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m-> 1024\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mdistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpdist\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1025\u001B[0m     y \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39masarray(y)\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.10/lib/python3.10/site-packages/scipy/spatial/distance.py:2180\u001B[0m, in \u001B[0;36mpdist\u001B[0;34m(X, metric, out, **kwargs)\u001B[0m\n\u001B[1;32m   2178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metric_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2179\u001B[0m     pdist_fn \u001B[38;5;241m=\u001B[39m metric_info\u001B[38;5;241m.\u001B[39mpdist_func\n\u001B[0;32m-> 2180\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpdist_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2181\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mstr\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m   2182\u001B[0m     metric_info \u001B[38;5;241m=\u001B[39m _TEST_METRICS\u001B[38;5;241m.\u001B[39mget(mstr, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mMemoryError\u001B[0m: Unable to allocate 265. GiB for an array with shape (35502197811,) and data type float64"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:43:49.312545Z",
     "start_time": "2024-12-07T10:43:49.287392Z"
    }
   },
   "cell_type": "code",
   "source": "df_scaled = df_scaled.astype('float32')  # o 'float16' si es aceptable",
   "id": "c5e33854215d231a",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T10:43:36.153068Z",
     "start_time": "2024-12-07T10:43:36.150020Z"
    }
   },
   "cell_type": "code",
   "source": "df_scaled = np.asarray(df_scaled)",
   "id": "3ba201d86496763b",
   "outputs": [],
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
