{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression Models",
   "id": "f3e514258553a974"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the regression task, our target variable will be the `AMT_CREDIT` column.",
   "id": "3c8e4febbbcf112b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First of all, we need to import the necessary libraries.",
   "id": "daba0e6e7fc6d451"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:14:27.948886Z",
     "start_time": "2024-12-21T12:14:27.933320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from random import random, Random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fontTools.misc.bezierTools import epsilon\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, TweedieRegressor, QuantileRegressor \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import optuna\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from statsmodels.sandbox.panel.sandwich_covariance_generic import kernel\n",
    "\n"
   ],
   "id": "46a4aa02f6fb21a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First of all, we are going to create a class to compute all the metrics. This class will be used to evaluate the performance of the models using the K Fold\n",
    "\n",
    "The Hyperparameter Tunning will be done using the Optuna library."
   ],
   "id": "5afb9d6f2ec75b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:14:32.258487Z",
     "start_time": "2024-12-21T12:14:32.229213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class RegressionMetrics:\n",
    "    def __init__(self, model, X, y):\n",
    "        self.model = model\n",
    "        self.X = pd.DataFrame(X).reset_index(drop=True)\n",
    "        self.y = pd.Series(y).reset_index(drop=True)\n",
    "        self.mse =[]\n",
    "        self.rmse = []\n",
    "        self.r2 = []\n",
    "        self.mae = []\n",
    "        self.mape = []\n",
    "        self.adj_r2 = []\n",
    "\n",
    "    def compute_metrics(self,y_test,y_pred):\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        self.mse.append(mse)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        self.rmse.append(rmse)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        self.r2.append(r2)\n",
    "\n",
    "        #adjusted r^2\n",
    "        n = len(self.X)\n",
    "        p = len(self.X.columns)\n",
    "        adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "        self.adj_r2.append(adj_r2)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        self.mae.append(mae)\n",
    "\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        self.mape.append(mape)\n",
    "\n",
    "    def Kfold_evaluation(self):\n",
    "        # skf = StratifiedKFold(n_splits=10, random_state=42,shuffle=True)\n",
    "        kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in kf.split(self.X,self.y):\n",
    "            # X_train = self.X.iloc[train_index, :]\n",
    "            # X_test = self.X.iloc[test_index, :]\n",
    "            # y_train = self.y[train_index]\n",
    "            # y_test = self.y[test_index]\n",
    "            X_train, X_test = self.X.iloc[train_index, :], self.X.iloc[test_index, :]\n",
    "            y_train, y_test = self.y.iloc[train_index], self.y.iloc[test_index]\n",
    "            self.model.fit(X_train, y_train)\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            self.compute_metrics(y_test,y_pred)\n",
    "\n",
    "    def printResults(self):\n",
    "        print(f'MSE: {np.mean(self.mse)}')\n",
    "        print(f'RMSE: {np.mean(self.rmse)}')\n",
    "        print(f'R2: {np.mean(self.r2)}')\n",
    "        print(f'MAE: {np.mean(self.mae)}')\n",
    "        print(f'MAPE: {np.mean(self.mape)}')\n",
    "        print(f'Adjusted R2: {np.mean(self.adj_r2)}')\n"
   ],
   "id": "962d4f5ab4b38315",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading the data.",
   "id": "ab973d156cadf075"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:14:36.822259Z",
     "start_time": "2024-12-21T12:14:36.542053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_parquet('../data/processed/selected_features_df.parquet')\n",
    "X = df.drop('AMT_CREDIT', axis=1)\n",
    "X = X.drop('AMT_GOODS_PRICE', axis=1)\n",
    "y = df['AMT_CREDIT']"
   ],
   "id": "a63518ebb41a3e50",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Standardizing the data.",
   "id": "26ce233a7a9ecfde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:14:40.966856Z",
     "start_time": "2024-12-21T12:14:38.952624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "id": "2fc750d134a367f0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lasso Regression",
   "id": "9c4d3c7bd5905e36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SelectFromModel is a meta-transformer that can be used along with any estimator that assigns importance to each feature through a coef_ or feature_importances_ attribute. The features are considered unimportant and removed, if the corresponding coef_ or feature_importances_ values are below the provided threshold parameter.",
   "id": "3cdfc9007494fc12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.001, max_iter=10000)\n",
    "selector = SelectFromModel(estimator=lasso)\n",
    "X_selected = selector.fit_transform(X_scaled, y)"
   ],
   "id": "8a9b96d403570e5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameter Tuning with Optuna\n",
   "id": "95b8a222c26ba6b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial):\n",
    "    tol = trial.suggest_float('tol', 1e-6, 1e-2, log = True)\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log = True)\n",
    "    lasso = Lasso(alpha=alpha, tol=tol, random_state=42, max_iter=10000)\n",
    "\n",
    "    cv_scores = cross_val_score(lasso, X_selected, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='Lasso Regression')\n",
    "study.optimize(objective, n_trials=3)"
   ],
   "id": "1e5b3101545083a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the model with the best found hyperparameters and compute the metrics.",
   "id": "bc560eb7ef2db799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = Lasso(**study.best_params, random_state=42, max_iter=10000)\n",
    "lasso_metrics = RegressionMetrics(model, X_selected, y)\n",
    "lasso_metrics.Kfold_evaluation()\n",
    "lasso_metrics.printResults()"
   ],
   "id": "77a396a5f8e7af59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualizing the study.",
   "id": "e81c2ad08cab0599"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "56798a2ae4ad94a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "894ed7a125034fad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Support Vector Regression (SVM) ",
   "id": "cafb3d4ca0af0493"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Optuna optimization study for tuning the hyperparameters of a SVR model. It aims to minimize the mean squared error (MSE) by adjusting the following parameters: \n",
    "\n",
    "* C: Regularization parameter\n",
    "* Epsilon : The tolerance margin for errors  in the prediction of the model\n",
    "* Kernel: Type of kernel use \n",
    "* Gamma: Kernel coefficient\n",
    "The model is evaluated using 5_fold_cross_validation and negative mean squared error(MSE). The goal is to maxime the performance by tunning the hyperparameters. "
   ],
   "id": "47b8cd81ec8f2449"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVR\n",
    "def objective (trial): \n",
    "    C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 0.01, 0.5)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'pòly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    svr = SVR( C=C, epsilon= epsilon, kernel=kernel, gamma=gamma)\n",
    "    \n",
    "    cv_scores = cross_val_score(svr, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study= optuna.create_study(direction = 'maximize', study_name= 'SVR Regression')\n",
    "study.optimize(objective, n_trials=3)\n",
    "    \n",
    "    \n",
    "    "
   ],
   "id": "850cdc5068b7143b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the model with the best found hyperparameters and compute SVR metrics ",
   "id": "be8b264fcf5d54ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "svr_model= SVR(**study.best_params, random_state=42)\n",
    "svr_metrics =RegressionMetrics(svr_model, X_selected, y)\n",
    "svr_metrics.Kfold_evaluation()\n",
    "svr_metrics.printResults()\n",
    "\n"
   ],
   "id": "cecdb93d2b279321"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Study Visualization",
   "id": "51bb62d5a9470302"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "47aa9071961d79d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "e1540a1ff0060b1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Nearest Neighbor Regression (KNN Regression)\n",
   "id": "3338b115b0e8019e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
    "    \n",
    "    knn_model = KNeighborsRegressor(n_neighbors=n_neighbors, metric=metric)\n",
    "    knn_metrics = RegressionMetrics(knn_model, X_scaled, y)\n",
    "    knn_metrics.Kfold_evaluation()\n",
    "    return np.mean(knn_metrics.mse)\n",
    "study = optuna.create_study(direction='minimize', study_name='KNN Regression')\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n"
   ],
   "id": "afa9538020e87045"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f892a1dddae2fa42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors= study.best_params['n_neighbours'], metric=study.best_params['metric'])\n",
    "knn_metrics=RegressionMetrics(knn_model, X_scaled, y)\n",
    "knn_metrics.Kfold_evaluation()\n",
    "knn_metrics.printResults()\n"
   ],
   "id": "18f758c5c5d1ce56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generalized Linear Regression",
   "id": "3f525476a12a20ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameter Tuning with Optuna",
   "id": "86997ecfb31356b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial):\n",
    "    power = trial.suggest_float('power', 1, 2)\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log=True)\n",
    "    tw = TweedieRegressor(power=power, alpha=alpha, max_iter=10000)\n",
    "    \n",
    "    cv_scores = cross_val_score(tw, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='Tweedie Regression')\n",
    "study.optimize(objective, n_trials=3)"
   ],
   "id": "ce211b7d2c25fddd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the model with the best found hyperparameters and compute the metrics",
   "id": "e3a7375506103356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = TweedieRegressor(**study.best_params, max_iter=10000)\n",
    "tweedie_metrics = RegressionMetrics(model, X_scaled, y)\n",
    "tweedie_metrics.Kfold_evaluation()\n",
    "tweedie_metrics.printResults()"
   ],
   "id": "79db62ac543507a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualizing the study",
   "id": "4363cea2df9ef125"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "44cd6fe7985188bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "55feff42dc359545"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Quantile Regression\n",
   "id": "98c818d02e0ef0f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Determine the solver based on de SciPy version\n",
   "id": "f9a22fea6e7d5342"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics._dist_metrics import parse_version\n",
    "from sklearn.utils.fixes import sp_version\n",
    "\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n"
   ],
   "id": "a7903430cefccbd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the quantiles",
   "id": "4a1934195ad19d4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "quantiles = [0.05, 0.5, 0.95]\n",
    "predictions = {}\n",
    "out_bounds_predictions = np.zeros_like(y, dtype=np.bool_)"
   ],
   "id": "ba06b8773f42e3f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameter Tuning with Optuna",
   "id": "9624b258bd2ecf46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log=True)\n",
    "    quantile = trial.suggest_categorical('quantile', quantiles)\n",
    "    qr = QuantileRegressor(alpha=alpha, quantile=quantile, solver=solver)\n",
    "\n",
    "    cv_scores = cross_val_score(qr, X_scaled, y, cv=3, scoring='neg_mean_squared_error')\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='Quantile Regression')\n",
    "study.optimize(objective, n_trials=3)"
   ],
   "id": "c2dcaf067a1be7d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fit the QuantileRegressor for each quantile using the best hyperparameters found",
   "id": "3e50546394133d29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for q in quantiles:\n",
    "    best_params = study.best_params\n",
    "    best_params['quantile'] = q\n",
    "    qr = QuantileRegressor(**best_params, solver=solver)\n",
    "    y_pred = qr.fit(X_scaled, y).predict(X_scaled)\n",
    "    predictions[q] = y_pred\n",
    "\n",
    "    if q == min(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(out_bounds_predictions, y_pred >= y)\n",
    "    elif q == max(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(out_bounds_predictions, y_pred <= y)"
   ],
   "id": "9d78e93896ae9e49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Plot the results",
   "id": "b20062bfec57ed83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(X_scaled, y, color=\"black\", linestyle=\"dashed\", label=\"True mean\")\n",
    "\n",
    "for quantile, y_pred in predictions.items():\n",
    "    plt.plot(X_scaled, y_pred, label=f\"Quantile: {quantile}\")\n",
    "\n",
    "plt.scatter(\n",
    "    X_scaled[out_bounds_predictions],\n",
    "    y[out_bounds_predictions],\n",
    "    color=\"black\",\n",
    "    marker=\"+\",\n",
    "    alpha=0.5,\n",
    "    label=\"Outside interval\",\n",
    ")\n",
    "plt.scatter(\n",
    "    X_scaled[~out_bounds_predictions],\n",
    "    y[~out_bounds_predictions],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"Inside interval\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"X_scaled\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Quantiles of heteroscedastic Normal distributed target\")\n",
    "plt.show()"
   ],
   "id": "9c936aed93320cfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Polynomial Regression\n",
   "id": "db1e9bd55e014ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create polynomial features",
   "id": "8989243cc3f1bfaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_features.fit_transform(X_scaled)"
   ],
   "id": "5152550e92abe184"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameter Tuning with Optuna",
   "id": "dbe2f9d4c982c0fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log=True)\n",
    "    model = LinearRegression()\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Perform optimization with Optuna\n",
    "study = optuna.create_study(direction='maximize', study_name='Polynomial Regression')\n",
    "study.optimize(objective, n_trials=3)"
   ],
   "id": "c800df4b502a9e29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the model with the best found hyperparameters and compute the metrics",
   "id": "d7d579fbcbdf3998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = LinearRegression()\n",
    "poly_metrics = RegressionMetrics(model, X_scaled, y)\n",
    "poly_metrics.Kfold_evaluation()\n",
    "poly_metrics.printResults()"
   ],
   "id": "771cc3d35cb387e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize the study",
   "id": "597de2701df1bda9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "a6ce6ccd74e45d77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "c49887438a71b800"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stochastic Gradient Descendent Regression ",
   "id": "7d50e462c3cf71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log=True)\n",
    "    tol = trial.suggest_float('tol', 1e-6, 1e-2, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 4600, step=500)\n",
    "    eta0 = trial.suggest_float('eta0', 1e-6, 1e-2, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']) \n",
    "    \n",
    "    sgd = SGDRegressor(alpha= alpha, tol = tol, max_iter=max_iter, eta0=eta0, penalty=penalty, random_state=42)\n",
    "    \n",
    "    cv_scores= cross_val_score(sgd, X_scaled, y , cv=5, scoring= 'neg_mean_squared_error')\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', study_name='SGDRegressor')\n",
    "\n",
    "study.optimize(objective, n_trials=3)\n",
    "    "
   ],
   "id": "90559db181e784c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sgd_model = SGDRegressor(**study.best_params, random_state=42)\n",
    "sgd_metrics=RegressionMetrics(sgd_model, X_scaled, y)\n",
    "sgd_metrics.Kfold_evaluation()\n",
    "sgd_metrics.printResults()\n"
   ],
   "id": "11f2388d44843d35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "e983636305e18d75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study)",
   "id": "36f50f9ea663cc5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest Regression ",
   "id": "7881097e3e96ea70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a267a861ba54751e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-21T13:02:56.453147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    " def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50,500, step= 50)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split= min_samples_split,min_samples_leaf= min_samples_leaf, max_features= max_features, random_state=42)\n",
    "    \n",
    "    cv_scores = cross_val_score(rf, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    return np.mean(cv_scores)\n",
    "study_rf = optuna.create_study(direction= 'maximize')\n",
    "study_rf.optimize(objective, n_trials=3)\n"
   ],
   "id": "6adbfd341b63079",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 14:02:56,453] A new study created in memory with name: no-name-c30a207f-4f42-44a9-8ec1-5d19df56aeb9\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-21T10:54:11.790118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_model = RandomForestRegressor(**study_rf.best_params, random_state=42)\n",
    "rf_metrics= RegressionMetrics(rf_model, X_scaled, y)\n",
    "rf_metrics.Kfold_evaluation()\n",
    "rf_metrics.printResults()"
   ],
   "id": "c3c3401e6fc5f013",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study_rf)\n",
   "id": "3f4d2f1bd047dbdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study_rf)",
   "id": "a7436c227187feb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Gaussian Process Regression\n",
   "id": "d02543a287b9f644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C \n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def objective(trial):\n",
    "    length_scale = trial.suggest_float('length_scale', 1e-5, 1e5, log=True)\n",
    "    constant_value = trial.suggest_float('constant_value', 1e-5, 1e5, log=True) \n",
    "    #We will calculate the kernel variable for the Gaussian Precess Regressor by multiplicating the ccurrent and the RBF kernel\n",
    "    kernel = C(constant_value, (1e-4, 1e1)) * RBF(length_scale, (1e-4,1e1))\n",
    "    gpr = GaussianProcessRegressor ( kernel= kernel, random_state=42)\n",
    "    \n",
    "    cv_scores = cross_val_score(gpr, X_scaled, cv=5, scoring= \"meg_mean_squared_error\")\n",
    "    \n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "study_gpr= optuna.create_study(direction = 'maximize')\n",
    "\n",
    "study_gpr.optimize(objective, n_trials=3)\n",
    "    \n",
    "    \n",
    " "
   ],
   "id": "e2ce6f3bcf892914"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "gps_params= study_gpr.best_params\n",
    "\n",
    "gps_kernel = C(gps_params['constant_value'], (1e-4, 1e1))* RBF(gps_params['lenght_scale'], (1e-4, 1e1))\n",
    "gps_model = GaussianProcessRegressor(kernel=kernel, random_state= 42)\n",
    "gps_model.fit(X_scaled, y)"
   ],
   "id": "8f49cffed17492b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_optimization_history(study_gpr)",
   "id": "f3e5959f7b413a7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optuna.visualization.plot_param_importances(study_gpr)",
   "id": "6a9c41e2cdf8c490"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
